{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1422be98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (50000, 32, 32, 3)\n",
      "50000  train samples\n",
      "10000  test samples\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               4194816   \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,200,842\n",
      "Trainable params: 4,200,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "313/313 [==============================] - 27s 83ms/step - loss: 1.7950 - accuracy: 0.3715 - val_loss: 1.3862 - val_accuracy: 0.5188\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 25s 80ms/step - loss: 1.3882 - accuracy: 0.5065 - val_loss: 1.2365 - val_accuracy: 0.5683\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 1.2523 - accuracy: 0.5600 - val_loss: 1.2690 - val_accuracy: 0.5615\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 21s 69ms/step - loss: 1.1642 - accuracy: 0.5922 - val_loss: 1.1359 - val_accuracy: 0.6042\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 23s 75ms/step - loss: 1.0938 - accuracy: 0.6160 - val_loss: 1.1536 - val_accuracy: 0.5945\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 27s 85ms/step - loss: 1.0402 - accuracy: 0.6359 - val_loss: 1.1009 - val_accuracy: 0.6211\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 0.9875 - accuracy: 0.6556 - val_loss: 1.0177 - val_accuracy: 0.6515\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 27s 87ms/step - loss: 0.9467 - accuracy: 0.6690 - val_loss: 1.0258 - val_accuracy: 0.6491\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 27s 85ms/step - loss: 0.9103 - accuracy: 0.6832 - val_loss: 1.1416 - val_accuracy: 0.6251\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 0.8733 - accuracy: 0.6955 - val_loss: 1.0889 - val_accuracy: 0.6450\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 25s 79ms/step - loss: 0.8444 - accuracy: 0.7080 - val_loss: 0.9672 - val_accuracy: 0.6765\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 0.8133 - accuracy: 0.7181 - val_loss: 1.0850 - val_accuracy: 0.6454\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 0.7855 - accuracy: 0.7283 - val_loss: 1.0052 - val_accuracy: 0.6681\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 25s 80ms/step - loss: 0.7594 - accuracy: 0.7368 - val_loss: 1.0194 - val_accuracy: 0.6622\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 0.7374 - accuracy: 0.7450 - val_loss: 1.1018 - val_accuracy: 0.6371\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 23s 75ms/step - loss: 0.7128 - accuracy: 0.7531 - val_loss: 1.0457 - val_accuracy: 0.6588\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 0.6915 - accuracy: 0.7600 - val_loss: 1.0575 - val_accuracy: 0.6679\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 0.6814 - accuracy: 0.7664 - val_loss: 1.0140 - val_accuracy: 0.6826\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 0.6583 - accuracy: 0.7732 - val_loss: 1.1019 - val_accuracy: 0.6563\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 0.6463 - accuracy: 0.7781 - val_loss: 1.1030 - val_accuracy: 0.6685\n",
      "79/79 [==============================] - 2s 27ms/step - loss: 1.1033 - accuracy: 0.6609\n",
      "Test score:  1.1032856702804565\n",
      "Test accuracy:  0.6608999967575073\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "# constants\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "# load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print(X_train.shape[0], ' train samples')\n",
    "print(X_test.shape[0], ' test samples')\n",
    "\n",
    "# convert to catagorical \n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same',\n",
    "                input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# network with 512 units and ReLU activation\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = BATCH_SIZE,\n",
    "          epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT,\n",
    "          verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "                      batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score: \", score[0])\n",
    "print('Test accuracy: ', score[1])\n",
    "\n",
    "# Save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "# Save weights\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c4481fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (50000, 32, 32, 3)\n",
      "50000  train samples\n",
      "10000  test samples\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 5, 5, 64)          36928     \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 2, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 2, 2, 64)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 202,282\n",
      "Trainable params: 202,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "313/313 [==============================] - 50s 157ms/step - loss: 1.9619 - accuracy: 0.2719 - val_loss: 1.7463 - val_accuracy: 0.3683\n",
      "Epoch 2/40\n",
      "313/313 [==============================] - 50s 158ms/step - loss: 1.6496 - accuracy: 0.3947 - val_loss: 1.4980 - val_accuracy: 0.4634\n",
      "Epoch 3/40\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 1.4830 - accuracy: 0.4573 - val_loss: 1.3680 - val_accuracy: 0.5076\n",
      "Epoch 4/40\n",
      "313/313 [==============================] - 39s 125ms/step - loss: 1.3741 - accuracy: 0.5027 - val_loss: 1.3978 - val_accuracy: 0.4990\n",
      "Epoch 5/40\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 1.2907 - accuracy: 0.5362 - val_loss: 1.1462 - val_accuracy: 0.5892\n",
      "Epoch 6/40\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 1.2203 - accuracy: 0.5643 - val_loss: 1.1170 - val_accuracy: 0.6081\n",
      "Epoch 7/40\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 1.1722 - accuracy: 0.5840 - val_loss: 1.1196 - val_accuracy: 0.6029\n",
      "Epoch 8/40\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 1.1292 - accuracy: 0.5974 - val_loss: 1.0479 - val_accuracy: 0.6348\n",
      "Epoch 9/40\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 1.0796 - accuracy: 0.6180 - val_loss: 0.9832 - val_accuracy: 0.6508\n",
      "Epoch 10/40\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 1.0476 - accuracy: 0.6280 - val_loss: 1.0069 - val_accuracy: 0.6436\n",
      "Epoch 11/40\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 1.0242 - accuracy: 0.6386 - val_loss: 0.9587 - val_accuracy: 0.6598\n",
      "Epoch 12/40\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 0.9926 - accuracy: 0.6497 - val_loss: 1.0183 - val_accuracy: 0.6551\n",
      "Epoch 13/40\n",
      "313/313 [==============================] - 41s 132ms/step - loss: 0.9702 - accuracy: 0.6563 - val_loss: 0.9501 - val_accuracy: 0.6708\n",
      "Epoch 14/40\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.9434 - accuracy: 0.6678 - val_loss: 0.9897 - val_accuracy: 0.6593\n",
      "Epoch 15/40\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 0.9304 - accuracy: 0.6703 - val_loss: 0.9646 - val_accuracy: 0.6606\n",
      "Epoch 16/40\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.9084 - accuracy: 0.6802 - val_loss: 0.8669 - val_accuracy: 0.6974\n",
      "Epoch 17/40\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.8976 - accuracy: 0.6874 - val_loss: 0.9037 - val_accuracy: 0.6854\n",
      "Epoch 18/40\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.8801 - accuracy: 0.6916 - val_loss: 0.8828 - val_accuracy: 0.7017\n",
      "Epoch 19/40\n",
      "313/313 [==============================] - 48s 152ms/step - loss: 0.8615 - accuracy: 0.6980 - val_loss: 0.8482 - val_accuracy: 0.7053\n",
      "Epoch 20/40\n",
      "313/313 [==============================] - 50s 160ms/step - loss: 0.8564 - accuracy: 0.7013 - val_loss: 1.0316 - val_accuracy: 0.6406\n",
      "Epoch 21/40\n",
      "313/313 [==============================] - 46s 146ms/step - loss: 0.8408 - accuracy: 0.7072 - val_loss: 0.8655 - val_accuracy: 0.7052\n",
      "Epoch 22/40\n",
      "313/313 [==============================] - 54s 174ms/step - loss: 0.8254 - accuracy: 0.7085 - val_loss: 0.8239 - val_accuracy: 0.7158\n",
      "Epoch 23/40\n",
      "313/313 [==============================] - 52s 168ms/step - loss: 0.8152 - accuracy: 0.7134 - val_loss: 0.8268 - val_accuracy: 0.7199\n",
      "Epoch 24/40\n",
      "313/313 [==============================] - 52s 168ms/step - loss: 0.8166 - accuracy: 0.7132 - val_loss: 0.8426 - val_accuracy: 0.7117\n",
      "Epoch 25/40\n",
      "313/313 [==============================] - 53s 168ms/step - loss: 0.8081 - accuracy: 0.7172 - val_loss: 0.9214 - val_accuracy: 0.6858\n",
      "Epoch 26/40\n",
      "313/313 [==============================] - 53s 170ms/step - loss: 0.7977 - accuracy: 0.7220 - val_loss: 0.9578 - val_accuracy: 0.6880\n",
      "Epoch 27/40\n",
      "313/313 [==============================] - 55s 174ms/step - loss: 0.7899 - accuracy: 0.7203 - val_loss: 0.8348 - val_accuracy: 0.7196\n",
      "Epoch 28/40\n",
      "313/313 [==============================] - 55s 175ms/step - loss: 0.7846 - accuracy: 0.7222 - val_loss: 0.8569 - val_accuracy: 0.7073\n",
      "Epoch 29/40\n",
      "313/313 [==============================] - 53s 170ms/step - loss: 0.7769 - accuracy: 0.7270 - val_loss: 0.7971 - val_accuracy: 0.7334\n",
      "Epoch 30/40\n",
      "313/313 [==============================] - 55s 175ms/step - loss: 0.7723 - accuracy: 0.7291 - val_loss: 0.9011 - val_accuracy: 0.7094\n",
      "Epoch 31/40\n",
      "313/313 [==============================] - 54s 172ms/step - loss: 0.7601 - accuracy: 0.7332 - val_loss: 0.8805 - val_accuracy: 0.7045\n",
      "Epoch 32/40\n",
      "313/313 [==============================] - 55s 177ms/step - loss: 0.7603 - accuracy: 0.7345 - val_loss: 0.8740 - val_accuracy: 0.7145\n",
      "Epoch 33/40\n",
      "313/313 [==============================] - 52s 166ms/step - loss: 0.7596 - accuracy: 0.7347 - val_loss: 0.8950 - val_accuracy: 0.6933\n",
      "Epoch 34/40\n",
      "313/313 [==============================] - 55s 176ms/step - loss: 0.7407 - accuracy: 0.7402 - val_loss: 0.8028 - val_accuracy: 0.7352\n",
      "Epoch 35/40\n",
      "313/313 [==============================] - 53s 170ms/step - loss: 0.7465 - accuracy: 0.7393 - val_loss: 0.8009 - val_accuracy: 0.7292\n",
      "Epoch 36/40\n",
      "313/313 [==============================] - 53s 168ms/step - loss: 0.7430 - accuracy: 0.7389 - val_loss: 0.8869 - val_accuracy: 0.7111\n",
      "Epoch 37/40\n",
      "313/313 [==============================] - 51s 162ms/step - loss: 0.7386 - accuracy: 0.7418 - val_loss: 0.8483 - val_accuracy: 0.7219\n",
      "Epoch 38/40\n",
      "313/313 [==============================] - 54s 172ms/step - loss: 0.7364 - accuracy: 0.7405 - val_loss: 0.8663 - val_accuracy: 0.7230\n",
      "Epoch 39/40\n",
      "313/313 [==============================] - 53s 169ms/step - loss: 0.7345 - accuracy: 0.7471 - val_loss: 0.8466 - val_accuracy: 0.7220\n",
      "Epoch 40/40\n",
      "313/313 [==============================] - 53s 168ms/step - loss: 0.7305 - accuracy: 0.7442 - val_loss: 0.9012 - val_accuracy: 0.7021\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.9151 - accuracy: 0.6980\n",
      "Test score:  0.9150885939598083\n",
      "Test accuracy:  0.6980000138282776\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "# constants\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 40\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "# load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print(X_train.shape[0], ' train samples')\n",
    "print(X_test.shape[0], ' test samples')\n",
    "\n",
    "# convert to catagorical \n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same',\n",
    "                input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# network with 512 units and ReLU activation\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = BATCH_SIZE,\n",
    "          epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT,\n",
    "          verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "                      batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score: \", score[0])\n",
    "print('Test accuracy: ', score[1])\n",
    "\n",
    "# Save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "# Save weights\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a54d5c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (50000, 32, 32, 3)\n",
      "50000  train samples\n",
      "10000  test samples\n",
      "Augmenting training set images...\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation_24 (Activation)  (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " activation_25 (Activation)  (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 16, 16, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " activation_26 (Activation)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 5, 5, 64)          36928     \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 2, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 2, 2, 64)          0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 202,282\n",
      "Trainable params: 202,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "313/313 [==============================] - 49s 155ms/step - loss: 1.9393 - accuracy: 0.2772 - val_loss: 1.7358 - val_accuracy: 0.3572\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 69s 220ms/step - loss: 1.6572 - accuracy: 0.3893 - val_loss: 1.4586 - val_accuracy: 0.4529\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 54s 173ms/step - loss: 1.5119 - accuracy: 0.4477 - val_loss: 1.4889 - val_accuracy: 0.4525\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 60s 191ms/step - loss: 1.4055 - accuracy: 0.4881 - val_loss: 1.3894 - val_accuracy: 0.4798\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 60s 190ms/step - loss: 1.3244 - accuracy: 0.5239 - val_loss: 1.2078 - val_accuracy: 0.5679\n",
      "Epoch 1/5\n",
      "313/313 [==============================] - 58s 185ms/step - loss: 1.2664 - accuracy: 0.5448 - val_loss: 1.2697 - val_accuracy: 0.5493\n",
      "Epoch 2/5\n",
      "165/313 [==============>...............] - ETA: 21s - loss: 1.2236 - accuracy: 0.5626"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 106>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    100\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mOPTIM,\n\u001b[0;32m    101\u001b[0m              metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    102\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train, batch_size \u001b[38;5;241m=\u001b[39m BATCH_SIZE,\n\u001b[0;32m    103\u001b[0m           epochs\u001b[38;5;241m=\u001b[39mNB_EPOCH, validation_split\u001b[38;5;241m=\u001b[39mVALIDATION_SPLIT,\n\u001b[0;32m    104\u001b[0m           verbose\u001b[38;5;241m=\u001b[39mVERBOSE)\n\u001b[1;32m--> 106\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNB_EPOCH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVALIDATION_SPLIT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVERBOSE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, Y_test,\n\u001b[0;32m    111\u001b[0m                       batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, verbose\u001b[38;5;241m=\u001b[39mVERBOSE)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest score: \u001b[39m\u001b[38;5;124m\"\u001b[39m, score[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "NUM_TO_AUGMENT = 5\n",
    "\n",
    "# constants\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 40\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "# load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print(X_train.shape[0], ' train samples')\n",
    "print(X_test.shape[0], ' test samples')\n",
    "\n",
    "# Augment\n",
    "print(\"Augmenting training set images...\")\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "xtas, ytas = [], []\n",
    "for i in range (X_train.shape[0]):\n",
    "    num_aug = 0\n",
    "    x = X_train[i] # (3, 32, 32)\n",
    "    x = x.reshape((1,) + x.shape) # (1, 3, 32, 32)\n",
    "for x_aug in datagen.flow(x, batch_size = 1,\n",
    "                         save_to_dir='preview',\n",
    "                         save_prefix='cifar',\n",
    "                         save_format='jpeg'):\n",
    "    if num_aug >= NUM_TO_AUGMENT:\n",
    "        break\n",
    "    xtas.append(x_aug[0])\n",
    "    num_aug += 1\n",
    "\n",
    "# convert to catagorical \n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same',\n",
    "                input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# network with 512 units and ReLU activation\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# train\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = BATCH_SIZE,\n",
    "          epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT,\n",
    "          verbose=VERBOSE)\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
    "    epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, \n",
    "    verbose=VERBOSE)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "                      batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Test score: \", score[0])\n",
    "print('Test accuracy: ', score[1])\n",
    "\n",
    "# Save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "# Save weights\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e725e7db",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.misc' has no attribute 'imresize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# load images\u001b[39;00m\n\u001b[0;32m     13\u001b[0m img_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat-standing.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdog.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 14\u001b[0m imgs \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mtranspose(scipy\u001b[38;5;241m.\u001b[39mmisc\u001b[38;5;241m.\u001b[39mimresize(scipy\u001b[38;5;241m.\u001b[39mmisc\u001b[38;5;241m.\u001b[39mimread(img_name),\n\u001b[0;32m     15\u001b[0m                                         (\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)),\n\u001b[0;32m     16\u001b[0m                     (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m        \u001b[38;5;28;01mfor\u001b[39;00m img_name \u001b[38;5;129;01min\u001b[39;00m img_names]\n\u001b[0;32m     18\u001b[0m imgs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(imgs) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# load images\u001b[39;00m\n\u001b[0;32m     13\u001b[0m img_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat-standing.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdog.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 14\u001b[0m imgs \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mtranspose(\u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmisc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimresize\u001b[49m(scipy\u001b[38;5;241m.\u001b[39mmisc\u001b[38;5;241m.\u001b[39mimread(img_name),\n\u001b[0;32m     15\u001b[0m                                         (\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)),\n\u001b[0;32m     16\u001b[0m                     (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m        \u001b[38;5;28;01mfor\u001b[39;00m img_name \u001b[38;5;129;01min\u001b[39;00m img_names]\n\u001b[0;32m     18\u001b[0m imgs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(imgs) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'scipy.misc' has no attribute 'imresize'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load model\n",
    "model_architecture = 'cifar10_architecture.json'\n",
    "model_weights = 'cifar10_weights.h5'\n",
    "model = model_from_json(open(model_architecture).read())\n",
    "model.load_weights(model_weights)\n",
    "\n",
    "# load images\n",
    "img_names = ['cat-standing.jpg', 'dog.jpg']\n",
    "imgs = [np.transpose(scipy.misc.imresize(scipy.misc.imread(img_name),\n",
    "                                        (32, 32)),\n",
    "                    (1, 0, 2)).astype('float32')\n",
    "       for img_name in img_names]\n",
    "imgs = np.array(imgs) / 255\n",
    "    \n",
    "# Train\n",
    "optim = SGD()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optim,\n",
    "    metrics=['accuracy'])\n",
    " \n",
    "# Predict\n",
    "predictions = model.predict_classes(imgs)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a28f663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc41046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa365ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assignment 3-2 : Identifying CIFAR-10 Images\n",
    "\n",
    "When considering what is ethical to 'train' a computer to recognize, human faces and their environment\n",
    "come to mind. Currently, there are a variety of consumer level products that use the technology\n",
    "to discern different people from one another, and this data is used for various purposes. However,\n",
    "is there cause for concern when these products are brought into our homes and allowed full access\n",
    "to our private life?\n",
    "\n",
    "One such product (as mentioned in a previous discussion post) is Meta's latest foray into the \n",
    "hardware market, the \"Portal\". Designed as a device that allows users to video chat with others\n",
    "or present to an audience from the comfort of your home, the Portal employs various technologies\n",
    "that allow it to recognize a person and follow them around the space that they are in. The details\n",
    "of how it does this are intricate, and as such this write-up will focus on the ethical concerns that\n",
    "users may or may not have when considering this technology.\n",
    "\n",
    "Various technology hubs have reported extensively on the Portal, and while the general consensus\n",
    "is that it is 'safe' and private, there are some concerns that have come to light regarding\n",
    "the data that the Portal has access to and transfers to Meta (the parent company of Facebook). Most\n",
    "alarmingly, Facebook has told various publications that it does in fact use Portal to collect various\n",
    "usage data in order to serve ads to users on other platforms (Terekhov). While this data collection is minimal\n",
    "(for now) it is still something that users should consider when purchasing a Portal.\n",
    "\n",
    "Digging deeper into the Portal and the technology within it's silicon, it can be assumed that the\n",
    "device is able to discern between different people within the home. If this is the case, the device\n",
    "could potentially be used to identify particular people and link them to various online profiles.\n",
    "Likewise, the technology must discern human faces from backgrounds, meaning that it must know what\n",
    "objects are in a persons home by simply viewing it. This implication leads one to believe that the\n",
    "device could potentially be used to build particular types of data profiles about users. Shopping\n",
    "habits, exercise schedules, even overall wealth could be devised based on background information\n",
    "in users' videos. While this is very much an extreme scenario, and Facebook has assured users that\n",
    "it does not collect any such data (Bates), the idea that it could potentially happen is worrisome. \n",
    "\n",
    "In general, any technology that can distinguish a person's face from another person's face is\n",
    "somewhat of cause for concern because such things are very rarely used for non-nefarious purposes.\n",
    "A person's face is the the main part of their uniqueness and their identification. Software trained\n",
    "to recognize peoples faces can be used to track them in real time like some TV shows would have us\n",
    "believe already takes place. They could be used to push very focused ad campaigns towards us and\n",
    "even help to shape our opinions about things like politics or ethics simply based on the demographic\n",
    "information found in our face. \n",
    "\n",
    "On the other end of the spectrum, if the trained algorithm was to be\n",
    "innacurate in discerning certain faces from others, this could result in other issues like \n",
    "accidental profiling or fugitive reporting in the event a crime was committed. The algorithm above\n",
    "only has an accuracy rating of 71% when viewing images of different animals. Human faces are far more\n",
    "complex and some can look very similar. Consider a suspect in a crime on the run, and facial \n",
    "recognition software attempting to track them reports any other person it spots that looks\n",
    "70% like the wanted individual. This would result in a lot of unecessary arrests and wasted time\n",
    "for the police, while the suspect could still pose a danger to the community. \n",
    "\n",
    "While facial recognizing software does have it's uses and has the potential to make some aspects\n",
    "of our daily lives easier, in this authors opinion the potential for negative uses far outweigh \n",
    "these benefits. Only in very regulated circumstances with total transparency should this technology\n",
    "be considered for use.\n",
    "\n",
    "References\n",
    "\n",
    "Bates, P. (2019, November 8). Can you trust facebook portal devices with your privacy? \n",
    "    MUO. Retrieved September 6, 2022, from \n",
    "    https://www.makeuseof.com/tag/trust-facebook-portal-privacy/ \n",
    "    \n",
    "Terekhov, A. (2018, November 8). Facebook portal privacy issues continue as it admits \n",
    "    to collecting user data. Hotspot Shield VPN. Retrieved September 6, 2022, from \n",
    "    https://www.hotspotshield.com/blog/facebook-portal-privacy/ \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
